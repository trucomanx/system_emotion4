{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa44d5b5-d58a-46c7-a457-1d981e158e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "## Because the KERAS used is a old verion, KERAS 1\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "## Allows memory allocation on the GPU to be done asynchronously, \n",
    "## potentially improving performance and efficiency in certain scenarios.\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "## Specify which GPUs are available to a program.\n",
    "## The list of GPUs is usually represented by indices starting at 0.\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # disable cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed521536-c3dd-4afd-a329-09522b2de9bf",
   "metadata": {},
   "source": [
    "# Install VideoImageTools\n",
    "\n",
    "To install VideoImageTools go to next link https://github.com/trucomanx/VideoImageTools\n",
    "\n",
    "# Install OpenPifPafTools\n",
    "\n",
    "To install OpenPifPafTools go to next link https://github.com/trucomanx/OpenPifPafTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35643409",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='testing_over_video.json';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec9de7-5010-475b-bed5-d18591b0964d",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a25d22-37d7-493d-858b-402c00224ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import platform, sys, os\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import VideoImageTools as vit\n",
    "import OpenPifPafTools.OpenPifPafAnnotations as opp\n",
    "import OpenPifPafTools.OpenPifPafGetData as oppgd\n",
    "\n",
    "import cv2\n",
    "import openpifpaf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aea137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 21:08:48.193897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-04 21:08:48.204682: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-04 21:08:48.208054: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-04 21:08:48.216057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 21:08:48.774276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725494929.188886 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.211547 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.211651 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30331932-18cb-42c2-81f5-57edb1a4b5da",
   "metadata": {},
   "source": [
    "# Biblioteca local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b632af2f-ad01-445c-86ac-419456eba3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4259e7e-375f-4f8a-bb1f-2dabd5d876c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SystemEmotion4Lib.Classifier as mylib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f1671-d398-4639-a577-b835e5714131",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087eb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eefba85-28a6-450d-a3a7-c71d4b23dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model of network\n",
    "dataset_name         = DATA['dataset_name']; # nome do dataset usado no treino\n",
    "\n",
    "checkpoint = DATA[\"checkpoint\"];\n",
    "model_type_body = DATA[\"model_type_body\"]; ## 'mobilenet_v3', 'efficientnet_b3', 'inception_v3', 'inception_resnet_v2', 'resnet_v2_50'\n",
    "model_type_face = DATA[\"model_type_face\"]; ## 'mobilenet_v3', 'efficientnet_b3', 'inception_v3', 'inception_resnet_v2', 'resnet_v2_50'\n",
    "model_type_skel = DATA[\"model_type_skel\"];\n",
    "model_type_fusion = DATA[\"model_type_fusion\"];\n",
    "enable_minus = DATA[\"enable_minus\"];\n",
    "\n",
    "vin_path = DATA['input_mp4_file'];\n",
    "\n",
    "output_base_dir = DATA['output_base_dir'];\n",
    "\n",
    "sub_dir='sub_dir1';\n",
    "\n",
    "body_factor=DATA['body_factor'];\n",
    "face_factor=DATA['face_factor'];\n",
    "face_detector_method=DATA['face_detector_method'];\n",
    "\n",
    "dimage_method=True;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfacf3b-046e-4426-b93f-fc4c335f1bf1",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a8d6f8-1547-4b3c-bb99-9975c49dd53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       checkpoint: shufflenetv2k16\n",
      "  model_type_body: efficientnet_b3\n",
      "  model_type_face: efficientnet_b3\n",
      "  model_type_skel: 20\n",
      "model_type_fusion: 11\n",
      "     enable_minus: False\n",
      "         vin_path: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/DATASET/TESE/PATIENT-RECOGNITION/PATIENT-VIDEOS/dataset-toy/drhouse_mini_cut.mp4\n",
      "  output_base_dir: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/OUTPUTS/DOCTORADO2/system_emotion4_1\n",
      "          sub_dir: 70b394495c04560405a4b2e32faed4de\n",
      "      body_factor: 0.95\n",
      "      face_factor: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if   sys.argv[n]=='--model-type-check':\n",
    "        checkpoint=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model-type-body':\n",
    "        model_type_body=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model-type-face':\n",
    "        model_type_face=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model-type-skel':\n",
    "        model_type_skel=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--model-type-fusion':\n",
    "        model_type_fusion=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--enable-minus':\n",
    "        enable_minus=sys.argv[n+1].lower()=='true';\n",
    "    elif sys.argv[n]=='--input-file':\n",
    "        vin_path=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--sub-dir':\n",
    "        sub_dir=sys.argv[n+1];\n",
    "\n",
    "\n",
    "INFO=dict();\n",
    "INFO[\"model_type_body\"] = model_type_body; \n",
    "INFO[\"model_type_face\"] = model_type_face;\n",
    "INFO[\"model_type_skel\"] = model_type_skel;\n",
    "INFO[\"model_type_fusion\"] = model_type_fusion;\n",
    "INFO[\"enable_minus\"] = enable_minus;\n",
    "INFO['body_factor'] = body_factor;\n",
    "INFO['face_factor'] = face_factor;\n",
    "INFO['face_detector_method'] = face_detector_method;\n",
    "\n",
    "# Serializar o dicionário em uma string JSON com uma ordenação consistente\n",
    "json_string = json.dumps(INFO, sort_keys=True)\n",
    "# Gerar um hash MD5 a partir da string JSON\n",
    "hash_object = hashlib.md5(json_string.encode())\n",
    "sub_dir = hash_object.hexdigest()\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('       checkpoint:',checkpoint);\n",
    "print('  model_type_body:',model_type_body);\n",
    "print('  model_type_face:',model_type_face);\n",
    "print('  model_type_skel:',model_type_skel);\n",
    "print('model_type_fusion:',model_type_fusion);\n",
    "print('     enable_minus:',enable_minus);\n",
    "print('         vin_path:',vin_path);\n",
    "print('  output_base_dir:',output_base_dir);\n",
    "print('          sub_dir:',sub_dir);\n",
    "print('      body_factor:',body_factor);\n",
    "print('      face_factor:',face_factor);\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440f607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vout_dir_path: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/OUTPUTS/DOCTORADO2/system_emotion4_1/ber2024-source/test_over_video/70b394495c04560405a4b2e32faed4de\n"
     ]
    }
   ],
   "source": [
    "vout_dir_path=os.path.join(output_base_dir,dataset_name,sub_dir,'test_over_video');\n",
    "print('vout_dir_path:',vout_dir_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb19658-0095-4134-82bc-97b0ded311ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vout_path: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/OUTPUTS/DOCTORADO2/system_emotion4_1/ber2024-source/test_over_video/70b394495c04560405a4b2e32faed4de/drhouse_mini_cut.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vout_path=os.path.join(vout_dir_path,os.path.basename(vin_path));\n",
    "print('vout_path:',vout_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adceab4-e767-415d-9a8b-9bd2373ba120",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c417d4-6024-40d1-b2bf-cc195c6695f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output_dir: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/OUTPUTS/DOCTORADO2/system_emotion4_1/ber2024-source/test_over_video/70b394495c04560405a4b2e32faed4de\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(vout_dir_path,exist_ok=True); \n",
    "print('Created output_dir:',vout_dir_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce5ea74-8a16-4971-b08e-f59b4bd92cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Salvando o dicionário como JSON\n",
    "with open(os.path.join(vout_dir_path,os.path.basename(vin_path)+\".json\"), \"w\") as file:\n",
    "    json.dump(INFO, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d720a7-2636-4700-a973-d3487dea314c",
   "metadata": {},
   "source": [
    "# Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fb32cf-a802-472d-a1d7-5f97c12ab6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "def extra_func(cap):\n",
    "    # Libera a memória da GPU no PyTorch\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Limpa a sessão atual e libera a memória da GPU no TensorFlow\n",
    "    tf.keras.backend.clear_session()\n",
    "    print('clean')\n",
    "\n",
    "def my_func(Clf,frame):\n",
    "    #categories=['angry','disgusted','fearful','happy','neutral','sad','surprised'];\n",
    "    categories=['negative','neutral','pain','positive'];\n",
    "    \n",
    "    img_tmp = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB);\n",
    "    pil_im = Image.fromarray(img_tmp);\n",
    "    \n",
    "    res, res_face, res_body, res_skel, face_bbox, body_bbox = Clf.predict_all_pil(pil_im);\n",
    "\n",
    "    if res is None:\n",
    "        return frame;\n",
    "    \n",
    "    res = np.argmax(res);\n",
    "    texto=categories[res];\n",
    "    \n",
    "    (xi,yi,xo,yo) = body_bbox;\n",
    "    \n",
    "    thickness=2;\n",
    "    \n",
    "    frame = cv2.putText(frame,\n",
    "                        texto,\n",
    "                        org = (int(xi), int((yi+yo)/2)),\n",
    "                        fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        fontScale = 2.0,\n",
    "                        color = (255, 0, 0),\n",
    "                        thickness = thickness\n",
    "                        );\n",
    "\n",
    "    color=(0,255,0);\n",
    "    cv2.rectangle(frame,(xi,yi),(xo,yo),color,thickness);\n",
    "\n",
    "    if isinstance(face_bbox, tuple):\n",
    "        (xi,yi,xo,yo) = face_bbox;\n",
    "        color=(0,0,255);\n",
    "        cv2.rectangle(frame,(xi,yi),(xo,yo),color,thickness);\n",
    "    \n",
    "    return frame;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4988749-3fbb-499e-8e56-e85486acdc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725494929.598270 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.598371 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.598437 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.654327 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725494929.654416 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 21:08:49.654472: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1725494929.654542 1364278 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 21:08:49.654604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10044 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transfer learning architecture efficientnet_b3\n",
      "        url: https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\n",
      "target_size: (300, 300)\n",
      "Loading the weights in: /home/fernando/.local/lib/python3.10/site-packages/FaceEmotion4Lib/models/model_efficientnet_b3.h5\n",
      "Loaded the weights in: /home/fernando/.local/lib/python3.10/site-packages/FaceEmotion4Lib/models/model_efficientnet_b3.h5\n",
      "\n",
      "Transfer learning architecture efficientnet_b3\n",
      "        url: https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\n",
      "target_size: (300, 300)\n",
      "Loading the weights in: /home/fernando/.local/lib/python3.10/site-packages/BodyEmotion4Lib/models/model_efficientnet_b3.h5\n",
      "Loaded the weights in: /home/fernando/.local/lib/python3.10/site-packages/BodyEmotion4Lib/models/model_efficientnet_b3.h5\n",
      "\n",
      "Loading the weights in: /home/fernando/.local/lib/python3.10/site-packages/SkeletonEmotion4Lib/models/model_onlycls_ncod20.h5\n",
      "Loaded the weights in: /home/fernando/.local/lib/python3.10/site-packages/SkeletonEmotion4Lib/models/model_onlycls_ncod20.h5\n",
      "\n",
      "Loading the weights in: /home/fernando/.local/lib/python3.10/site-packages/FusionEmotion4Lib/models/model_ncod11.h5\n",
      "Loaded the weights in: /home/fernando/.local/lib/python3.10/site-packages/FusionEmotion4Lib/models/model_ncod11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                         [ time left: ? ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/openpifpaf/csrc/src/cif_hr.cpp:102: UserInfo: resizing cifhr buffer\n",
      "src/openpifpaf/csrc/src/occupancy.cpp:53: UserInfo: resizing occupancy buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 21:09:04.677121: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1725494944.688381 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.713117 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.713891 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.714683 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.715463 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.720931 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.722411 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.723734 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.724990 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.725933 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.816748 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.818244 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.819765 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.820605 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.821439 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.822272 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.823098 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.829834 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.831422 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.833112 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.834695 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.836374 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.842392 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.843340 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.844826 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.845727 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.847229 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.848763 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.850522 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.851448 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.853110 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725494944.854702 1364378 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "Processing: |                                         [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo criado com sucesso em: /mnt/8811f502-ae19-4dd8-8371-f1915178f581/Fernando/OUTPUTS/DOCTORADO2/system_emotion4_1/ber2024-source/test_over_video/70b394495c04560405a4b2e32faed4de/drhouse_mini_cut.mp4\n",
      "working end\n"
     ]
    }
   ],
   "source": [
    "Clf=mylib.Emotion4Classifier(   checkpoint=checkpoint,\n",
    "                                model_type_face=model_type_face,\n",
    "                                model_type_body=model_type_body,\n",
    "                                model_type_skel=model_type_skel,\n",
    "                                model_type_skel_enable_minus=enable_minus,\n",
    "                                model_type_fusion=model_type_fusion,\n",
    "                                body_factor=body_factor,\n",
    "                                face_factor=face_factor,\n",
    "                                face_detector_method=face_detector_method);\n",
    "\n",
    "if dimage_method==True:\n",
    "    ## Crio pasata com imagens\n",
    "    vout_dir_tmp=os.path.join(vout_dir_path,os.path.splitext(os.path.basename(vin_path))[0]);\n",
    "    image_files, fps = vit.apply_func_predictor_over_video_to_frames(my_func,Clf,vin_path,vout_dir_tmp, show=False,FORMATO = \"frame_{:05d}.png\");\n",
    "    \n",
    "    ## Save frames to video\n",
    "    vit.images_to_video(image_files, fps, vout_path)\n",
    "else:\n",
    "    vit.apply_func_predictor_over_video_outmp4(my_func,Clf,vin_path,vout_path,extra_func_counter=1024,extra_func=extra_func)\n",
    "\n",
    "print('working end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6af90c-883b-4e81-bc88-2cd3ed7c9d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
